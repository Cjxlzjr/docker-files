# See: https://github.com/cloudera/hue/blob/master/desktop/conf.dist/hue.ini
# ==================================

[desktop]
  secret_key=gCDil4ehVBuSHayoXhtB8opaEE0MFBXZR6WEV2VLZBd

  http_host=0.0.0.0
  http_port=8888

  time_zone=Asia/Tokyo
  django_debug_mode=false
  http_500_debug_mode=false

  app_blacklist=spark,zookeeper,hbase,search,jobsub,pig,sqoop,security,impala,oozie

  gunicorn_work_class=gevent

  enable_prometheus=true
  
  auth_username=hue
  server_user=hue

  [[database]]
    engine=mysql
    host=database
    port=3306
    user=root
    password=D4EfSXVWMr84
    name=hue_db

[notebook]
  show_notebooks=true
  enable_external_statements=true
  enable_query_builder=true

  [[interpreters]]
    [[[mysql]]]
      name = MySQL
      interface=sqlalchemy
      options='{"url": "mysql://root:D4EfSXVWMr84@database:3306/hue_db"}'
 
    [[[hive]]]
      name=Hive
      interface=hiveserver2
      options='{"server_host": "hive-server", "server_port": 10002}'

    [[[impala]]]
      name=Impala
      interface=hiveserver2

    [[[text]]]
      name=Text
      interface=text

    [[[markdown]]]
      name=Markdown
      interface=text

    [[[sparksql]]]
      name=Spark SQL
      interface=hiveserver2
      options='{"url": "hive://root@localhost:10001/default"}'
      


[dashboard]
  has_sql_enabled=true

[hadoop]
  [[hdfs_clusters]]
    [[[default]]]
      fs_defaultfs=hdfs://namenode:9000
      webhdfs_url=http://namenode:9870/webhdfs/v1

  [[yarn_clusters]]
    [[[default]]]
      resourcemanager_host=http://resourcemanager
      resourcemanager_port=8032
      logical_name=yarnRM
      resourcemanager_api_url=http://resourcemanager:8088
      proxy_api_url=http://resourcemanager:8088
      history_server_api_url=http://historyserver:8188
      # spark_history_server_url=http://localhost:18088

[beeswax]

  hive_server_host=hive-server
  hive_server_port=10000

  thrift_version=7

  hive_discovery_llap = false
  hive_discovery_hs2 = false
  # hive_discovery_hiveserver2_znode = /hiveserver2

  hive_metastore_host=	hive-metastore
  hive_metastore_port=9083

  hive_conf_dir=/etc/hive/conf 

  list_partitions_limit=1000000
  download_row_limit=-1
  download_bytes_limit=-1
  close_queries=false


# [impala]

#   server_host=my-cdh-w01.example.com
#   server_port=21050

#   config_whitelist='{"debug_action", "explain_level", "mem_limit", "optimize_partition_key_scans", "query_timeout_s", "request_pool"}'

#[spark]
# sql_server_port=10001
# sql_server_host=spark-sql-server
# spark_home=/spark
# [filebrowser]
#   remote_storage_home=s3a://my-backet

# [hbase]

# [search]

# [liboozie]

# [jobbrowser]

#   share_jobs=true
#   log_offset=-100000000
#   max_job_fetch=5000
#   enable_v2=true
#   enable_query_browser=true
#   enable_queries_list=true

#   [[query_store]]

# [aws]
#   [[aws_accounts]]
#     [[[default]]]
#       access_key_id=AKIAIOSFODNN7EXAMPLE
#       secret_access_key=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
#       region=ap-northeast-1

# [azure]
#   [[azure_accounts]]
#     [[[default]]]

#   [[adls_clusters]]
#     [[[default]]]

# [libzookeeper]
#   ensemble=namenode:2181,my-cdh-m02.example.com:2182,my-cdh-m03.example.com:2183

# [kafka]
#   [[kafka]]

# [metadata]
#   [[optimizer]]
#     mode=local
